{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corall Recommendation Engine Exploration\n",
    "\n",
    "This notebook helps explore how the recommendation engine works by:\n",
    "- Loading papers from Zotero\n",
    "- Computing similarity matrices\n",
    "- Analyzing citation networks\n",
    "- Visualizing recommendation scores\n",
    "\n",
    "Data is saved to `Test_Data/` directory (excluded from git)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path to import Corall modules\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from src.zotero_client import ZoteroClient\n",
    "from src.openalex_client import OpenAlexClient\n",
    "from src.similarity_engine import SimilarityEngine\n",
    "from src.citation_scorer import CitationScorer\n",
    "from src.recommender import PaperRecommender\n",
    "\n",
    "# Create Test_Data directory if it doesn't exist\n",
    "TEST_DATA_DIR = Path('Test_Data')\n",
    "TEST_DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "print(f\"✓ Test data directory: {TEST_DATA_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Papers from Zotero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Zotero client\n",
    "zotero = ZoteroClient()\n",
    "\n",
    "# Fetch library papers\n",
    "print(\"Fetching papers from Zotero...\")\n",
    "library_papers = zotero.fetch_library()\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(library_papers)} papers from Zotero\")\n",
    "print(f\"  Papers with DOI: {sum(1 for p in library_papers if p.get('doi'))}\")\n",
    "print(f\"  Papers with abstract: {sum(1 for p in library_papers if p.get('abstract'))}\")\n",
    "\n",
    "# Save to Test_Data\n",
    "with open(TEST_DATA_DIR / 'library_papers.pkl', 'wb') as f:\n",
    "    pickle.dump(library_papers, f)\n",
    "    \n",
    "print(f\"\\n✓ Saved to {TEST_DATA_DIR / 'library_papers.pkl'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few papers\n",
    "df_papers = pd.DataFrame([{\n",
    "    'title': p.get('title', '')[:60] + '...' if len(p.get('title', '')) > 60 else p.get('title', ''),\n",
    "    'year': p.get('year', ''),\n",
    "    'has_doi': bool(p.get('doi')),\n",
    "    'has_abstract': bool(p.get('abstract')),\n",
    "    'num_authors': len(p.get('authors', []))\n",
    "} for p in library_papers[:10]])\n",
    "\n",
    "print(\"Sample papers:\")\n",
    "df_papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize similarity engine\n",
    "similarity_engine = SimilarityEngine()\n",
    "\n",
    "print(\"Building library profile (computing embeddings)...\")\n",
    "print(\"This may take a few minutes for large libraries...\\n\")\n",
    "\n",
    "similarity_engine.build_library_profile(library_papers)\n",
    "\n",
    "print(f\"\\n✓ Generated embeddings for {len(similarity_engine.library_embeddings)} papers\")\n",
    "print(f\"  Embedding dimension: {similarity_engine.library_embeddings[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pairwise similarity matrix\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "n_papers = len(similarity_engine.library_embeddings)\n",
    "similarity_matrix = np.zeros((n_papers, n_papers))\n",
    "\n",
    "print(f\"Computing {n_papers}x{n_papers} similarity matrix...\")\n",
    "\n",
    "for i in range(n_papers):\n",
    "    for j in range(i, n_papers):\n",
    "        if i == j:\n",
    "            similarity_matrix[i, j] = 1.0\n",
    "        else:\n",
    "            sim = 1 - cosine(similarity_engine.library_embeddings[i], \n",
    "                           similarity_engine.library_embeddings[j])\n",
    "            similarity_matrix[i, j] = sim\n",
    "            similarity_matrix[j, i] = sim\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"  Progress: {i+1}/{n_papers}\")\n",
    "\n",
    "print(f\"\\n✓ Similarity matrix computed: {similarity_matrix.shape}\")\n",
    "\n",
    "# Save to Test_Data\n",
    "np.save(TEST_DATA_DIR / 'similarity_matrix.npy', similarity_matrix)\n",
    "print(f\"✓ Saved to {TEST_DATA_DIR / 'similarity_matrix.npy'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize similarity matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(similarity_matrix, cmap='RdYlGn', vmin=0, vmax=1, \n",
    "            cbar_kws={'label': 'Cosine Similarity'})\n",
    "plt.title(f'Paper Similarity Matrix ({n_papers} papers)', fontsize=14, pad=20)\n",
    "plt.xlabel('Paper Index')\n",
    "plt.ylabel('Paper Index')\n",
    "plt.tight_layout()\n",
    "plt.savefig(TEST_DATA_DIR / 'similarity_matrix_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Saved visualization to {TEST_DATA_DIR / 'similarity_matrix_heatmap.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity statistics\n",
    "# Get upper triangle (excluding diagonal)\n",
    "upper_triangle = similarity_matrix[np.triu_indices_from(similarity_matrix, k=1)]\n",
    "\n",
    "print(\"Similarity Statistics:\")\n",
    "print(f\"  Mean similarity: {upper_triangle.mean():.3f}\")\n",
    "print(f\"  Median similarity: {np.median(upper_triangle):.3f}\")\n",
    "print(f\"  Std deviation: {upper_triangle.std():.3f}\")\n",
    "print(f\"  Min similarity: {upper_triangle.min():.3f}\")\n",
    "print(f\"  Max similarity: {upper_triangle.max():.3f}\")\n",
    "print(f\"  25th percentile: {np.percentile(upper_triangle, 25):.3f}\")\n",
    "print(f\"  75th percentile: {np.percentile(upper_triangle, 75):.3f}\")\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(upper_triangle, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(upper_triangle.mean(), color='red', linestyle='--', label=f'Mean: {upper_triangle.mean():.3f}')\n",
    "plt.axvline(np.median(upper_triangle), color='green', linestyle='--', label=f'Median: {np.median(upper_triangle):.3f}')\n",
    "plt.xlabel('Cosine Similarity', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('Distribution of Paper Similarities', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(TEST_DATA_DIR / 'similarity_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Saved distribution plot to {TEST_DATA_DIR / 'similarity_distribution.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Citation Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize clients\n",
    "openalex = OpenAlexClient()\n",
    "citation_scorer = CitationScorer()\n",
    "\n",
    "print(\"Building citation network from OpenAlex...\")\n",
    "print(\"This will query OpenAlex for each paper in your library.\")\n",
    "print(\"May take several minutes...\\n\")\n",
    "\n",
    "citation_scorer.build_library_network(openalex, library_papers)\n",
    "\n",
    "print(f\"\\n✓ Citation network built\")\n",
    "print(f\"  Total works in network: {len(citation_scorer.library_network)}\")\n",
    "print(f\"  Library papers mapped: {len([p for p in library_papers if p.get('openalex_id')])}\")\n",
    "\n",
    "# Save to Test_Data\n",
    "with open(TEST_DATA_DIR / 'citation_network.pkl', 'wb') as f:\n",
    "    pickle.dump(citation_scorer.library_network, f)\n",
    "    \n",
    "print(f\"\\n✓ Saved to {TEST_DATA_DIR / 'citation_network.pkl'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Citation network statistics\n",
    "network_size = len(citation_scorer.library_network)\n",
    "library_size = len(library_papers)\n",
    "mapped_papers = len([p for p in library_papers if p.get('openalex_id')])\n",
    "\n",
    "print(\"Citation Network Statistics:\")\n",
    "print(f\"  Library papers: {library_size}\")\n",
    "print(f\"  Papers mapped to OpenAlex: {mapped_papers} ({mapped_papers/library_size*100:.1f}%)\")\n",
    "print(f\"  Total works in network: {network_size}\")\n",
    "print(f\"  Network expansion factor: {network_size/max(mapped_papers, 1):.1f}x\")\n",
    "\n",
    "# Save statistics\n",
    "stats = {\n",
    "    'library_size': library_size,\n",
    "    'mapped_papers': mapped_papers,\n",
    "    'network_size': network_size,\n",
    "    'expansion_factor': network_size/max(mapped_papers, 1)\n",
    "}\n",
    "\n",
    "with open(TEST_DATA_DIR / 'citation_stats.json', 'w') as f:\n",
    "    json.dump(stats, f, indent=2)\n",
    "    \n",
    "print(f\"\\n✓ Saved statistics to {TEST_DATA_DIR / 'citation_stats.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Recommendation Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recent papers for testing\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Search for papers from last 7 days\n",
    "from_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"Searching for recent papers (from {from_date})...\")\n",
    "print(\"Note: This uses default journal filtering\\n\")\n",
    "\n",
    "# Note: This may take a while depending on journal filters\n",
    "# For testing, you might want to limit the number of papers\n",
    "test_candidates = openalex.search_recent_papers(\n",
    "    from_date=from_date,\n",
    "    limit=50  # Limit to 50 for faster testing\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Found {len(test_candidates)} candidate papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute scores for test candidates\n",
    "print(\"Computing similarity scores...\")\n",
    "test_candidates = similarity_engine.compute_similarity(test_candidates)\n",
    "\n",
    "print(\"Computing citation scores...\")\n",
    "test_candidates = citation_scorer.compute_citation_scores(test_candidates)\n",
    "\n",
    "# Compute combined scores\n",
    "citation_weight = 0.3\n",
    "similarity_weight = 0.7\n",
    "\n",
    "for paper in test_candidates:\n",
    "    paper['combined_score'] = (\n",
    "        citation_weight * paper.get('citation_score', 0) +\n",
    "        similarity_weight * paper.get('similarity_score', 0)\n",
    "    )\n",
    "\n",
    "# Sort by combined score\n",
    "test_candidates.sort(key=lambda x: x['combined_score'], reverse=True)\n",
    "\n",
    "print(f\"\\n✓ Scored {len(test_candidates)} papers\")\n",
    "\n",
    "# Save to Test_Data\n",
    "with open(TEST_DATA_DIR / 'test_recommendations.pkl', 'wb') as f:\n",
    "    pickle.dump(test_candidates, f)\n",
    "    \n",
    "print(f\"✓ Saved to {TEST_DATA_DIR / 'test_recommendations.pkl'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top recommendations\n",
    "print(\"\\nTop 10 Recommendations:\\n\" + \"=\"*60)\n",
    "\n",
    "for i, paper in enumerate(test_candidates[:10], 1):\n",
    "    title = paper.get('title', 'Unknown')[:60] + '...' if len(paper.get('title', '')) > 60 else paper.get('title', 'Unknown')\n",
    "    combined = paper.get('combined_score', 0)\n",
    "    citation = paper.get('citation_score', 0)\n",
    "    similarity = paper.get('similarity_score', 0)\n",
    "    \n",
    "    print(f\"\\n{i}. {title}\")\n",
    "    print(f\"   Combined: {combined:.3f} | Citation: {citation:.3f} | Similarity: {similarity:.3f}\")\n",
    "    \n",
    "    most_similar = paper.get('most_similar_paper')\n",
    "    if most_similar:\n",
    "        similar_title = most_similar.get('title', 'Unknown')[:50] + '...' if len(most_similar.get('title', '')) > 50 else most_similar.get('title', 'Unknown')\n",
    "        print(f\"   Most similar to: \\\"{similar_title}\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize score distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Combined scores\n",
    "combined_scores = [p.get('combined_score', 0) for p in test_candidates]\n",
    "axes[0, 0].hist(combined_scores, bins=30, edgecolor='black', alpha=0.7, color='purple')\n",
    "axes[0, 0].set_xlabel('Combined Score')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Combined Score Distribution')\n",
    "axes[0, 0].axvline(np.mean(combined_scores), color='red', linestyle='--', label=f'Mean: {np.mean(combined_scores):.3f}')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Citation scores\n",
    "citation_scores = [p.get('citation_score', 0) for p in test_candidates]\n",
    "axes[0, 1].hist(citation_scores, bins=30, edgecolor='black', alpha=0.7, color='red')\n",
    "axes[0, 1].set_xlabel('Citation Score')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Citation Score Distribution')\n",
    "axes[0, 1].axvline(np.mean(citation_scores), color='darkred', linestyle='--', label=f'Mean: {np.mean(citation_scores):.3f}')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Similarity scores\n",
    "similarity_scores = [p.get('similarity_score', 0) for p in test_candidates]\n",
    "axes[1, 0].hist(similarity_scores, bins=30, edgecolor='black', alpha=0.7, color='blue')\n",
    "axes[1, 0].set_xlabel('Similarity Score')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Similarity Score Distribution')\n",
    "axes[1, 0].axvline(np.mean(similarity_scores), color='darkblue', linestyle='--', label=f'Mean: {np.mean(similarity_scores):.3f}')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Scatter: Citation vs Similarity\n",
    "axes[1, 1].scatter(citation_scores, similarity_scores, alpha=0.6, s=50)\n",
    "axes[1, 1].set_xlabel('Citation Score')\n",
    "axes[1, 1].set_ylabel('Similarity Score')\n",
    "axes[1, 1].set_title('Citation vs Similarity Scores')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "# Add correlation\n",
    "correlation = np.corrcoef(citation_scores, similarity_scores)[0, 1]\n",
    "axes[1, 1].text(0.05, 0.95, f'Correlation: {correlation:.3f}', \n",
    "               transform=axes[1, 1].transAxes, verticalalignment='top',\n",
    "               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(TEST_DATA_DIR / 'score_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Saved score visualizations to {TEST_DATA_DIR / 'score_distributions.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Most Similar Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count which library papers are most frequently matched\n",
    "from collections import Counter\n",
    "\n",
    "most_similar_titles = []\n",
    "for paper in test_candidates:\n",
    "    most_similar = paper.get('most_similar_paper')\n",
    "    if most_similar:\n",
    "        most_similar_titles.append(most_similar.get('title', 'Unknown'))\n",
    "\n",
    "title_counts = Counter(most_similar_titles)\n",
    "\n",
    "print(\"Top 10 Most Frequently Matched Library Papers:\\n\" + \"=\"*60)\n",
    "for i, (title, count) in enumerate(title_counts.most_common(10), 1):\n",
    "    display_title = title[:70] + '...' if len(title) > 70 else title\n",
    "    print(f\"{i}. {display_title}\")\n",
    "    print(f\"   Matched {count} times ({count/len(test_candidates)*100:.1f}% of recommendations)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "summary = {\n",
    "    'library': {\n",
    "        'total_papers': len(library_papers),\n",
    "        'papers_with_doi': sum(1 for p in library_papers if p.get('doi')),\n",
    "        'papers_with_abstract': sum(1 for p in library_papers if p.get('abstract')),\n",
    "    },\n",
    "    'similarity': {\n",
    "        'mean_similarity': float(upper_triangle.mean()),\n",
    "        'median_similarity': float(np.median(upper_triangle)),\n",
    "        'std_similarity': float(upper_triangle.std()),\n",
    "    },\n",
    "    'citation_network': {\n",
    "        'network_size': len(citation_scorer.library_network),\n",
    "        'mapped_papers': len([p for p in library_papers if p.get('openalex_id')]),\n",
    "    },\n",
    "    'recommendations': {\n",
    "        'num_candidates': len(test_candidates),\n",
    "        'mean_combined_score': float(np.mean(combined_scores)),\n",
    "        'mean_citation_score': float(np.mean(citation_scores)),\n",
    "        'mean_similarity_score': float(np.mean(similarity_scores)),\n",
    "        'citation_similarity_correlation': float(correlation),\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "with open(TEST_DATA_DIR / 'analysis_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nLibrary:\")\n",
    "print(f\"  Total papers: {summary['library']['total_papers']}\")\n",
    "print(f\"  Papers with DOI: {summary['library']['papers_with_doi']}\")\n",
    "print(f\"  Papers with abstract: {summary['library']['papers_with_abstract']}\")\n",
    "\n",
    "print(f\"\\nSimilarity Matrix:\")\n",
    "print(f\"  Mean similarity: {summary['similarity']['mean_similarity']:.3f}\")\n",
    "print(f\"  Median similarity: {summary['similarity']['median_similarity']:.3f}\")\n",
    "print(f\"  Std deviation: {summary['similarity']['std_similarity']:.3f}\")\n",
    "\n",
    "print(f\"\\nCitation Network:\")\n",
    "print(f\"  Network size: {summary['citation_network']['network_size']} works\")\n",
    "print(f\"  Mapped papers: {summary['citation_network']['mapped_papers']}\")\n",
    "\n",
    "print(f\"\\nRecommendations:\")\n",
    "print(f\"  Candidates tested: {summary['recommendations']['num_candidates']}\")\n",
    "print(f\"  Mean combined score: {summary['recommendations']['mean_combined_score']:.3f}\")\n",
    "print(f\"  Mean citation score: {summary['recommendations']['mean_citation_score']:.3f}\")\n",
    "print(f\"  Mean similarity score: {summary['recommendations']['mean_similarity_score']:.3f}\")\n",
    "print(f\"  Citation-Similarity correlation: {summary['recommendations']['citation_similarity_correlation']:.3f}\")\n",
    "\n",
    "print(f\"\\n✓ Saved summary to {TEST_DATA_DIR / 'analysis_summary.json'}\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated Files\n",
    "\n",
    "All data is saved to `Test_Data/` directory:\n",
    "\n",
    "- `library_papers.pkl` - Your Zotero library papers\n",
    "- `similarity_matrix.npy` - Full similarity matrix (NxN)\n",
    "- `similarity_matrix_heatmap.png` - Visualization of similarity matrix\n",
    "- `similarity_distribution.png` - Distribution of similarity scores\n",
    "- `citation_network.pkl` - Citation network from OpenAlex\n",
    "- `citation_stats.json` - Citation network statistics\n",
    "- `test_recommendations.pkl` - Test candidate papers with scores\n",
    "- `score_distributions.png` - Score distribution visualizations\n",
    "- `analysis_summary.json` - Complete analysis summary\n",
    "\n",
    "**Note:** `Test_Data/` is excluded from git to save space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
